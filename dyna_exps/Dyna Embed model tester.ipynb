{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T09:30:20.887251Z",
     "start_time": "2020-05-07T09:30:20.851883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/viresh16118/repos/jodie\n"
     ]
    }
   ],
   "source": [
    "%cd /home/viresh16118/repos/jodie/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T09:30:55.908581Z",
     "start_time": "2020-05-07T09:30:55.890826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T12:29:58.331142Z",
     "start_time": "2020-05-07T12:29:58.326165Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import defaultdict\n",
    "import dyna_loader as dnldr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T09:36:35.328527Z",
     "start_time": "2020-05-07T09:33:04.797556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading network from /home/viresh16118/ICDM_Computed/stackoverflow/feature_extracted.pkl and /home/viresh16118/ICDM_Computed/stackoverflow/id_to_body.pkl\n",
      "Formating item sequence\n",
      "Formating user sequence\n",
      "Formatting original poster sequence\n",
      "Scaling Timestamps\n",
      "*** Network loading completed ***\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "[user2id, user_sequence_id, \n",
    " user_timedifference_sequence, \n",
    " user_previous_itemid_sequence, \n",
    " op_sequence_id, \n",
    " op_timedifference_sequence, \n",
    " item2id, item_sequence_id, \n",
    " item_timedifference_sequence, \n",
    " timestamp_sequence, \n",
    " feature_sequence, \n",
    " y_true_labels] = dnldr.load_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what actually is inside jodie's contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T09:40:34.458644Z",
     "start_time": "2020-05-07T09:40:34.151347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1397086.0, 1397086)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_true_labels), len(y_true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T09:43:52.044490Z",
     "start_time": "2020-05-07T09:43:52.028990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Network statistics:\n",
      "  90182 users\n",
      "  19911 items\n",
      "  1397086 interactions\n",
      "  73 feature size ***\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_interactions = len(user_sequence_id)\n",
    "num_users = len(user2id) \n",
    "num_items = len(item2id) + 1 # one extra item for \"none-of-these\"\n",
    "num_features = len(feature_sequence[0])\n",
    "print(\"*** Network statistics:\\n  %d users\\n  %d items\\n  %d interactions\\n  %d feature size ***\\n\\n\" % (num_users, num_items, num_interactions, num_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T09:46:12.000563Z",
     "start_time": "2020-05-07T09:46:11.992885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5355.894\n"
     ]
    }
   ],
   "source": [
    "train_proportion = 0.8\n",
    "train_end_idx = validation_start_idx = int(num_interactions * train_proportion) \n",
    "test_start_idx = int(num_interactions * (train_proportion+0.1))\n",
    "test_end_idx = int(num_interactions * (train_proportion+0.2))\n",
    "\n",
    "timespan = timestamp_sequence[-1] - timestamp_sequence[0]\n",
    "tbatch_timespan = timespan / 500 \n",
    "print(tbatch_timespan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T10:08:19.579206Z",
     "start_time": "2020-05-07T10:08:19.531773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function <lambda> at 0x7f0c3db61c80>, {})\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 128\n",
    "initial_userembeddings = F.normalize(torch.randn(embedding_dim), dim=0)\n",
    "initial_itemembeddings = F.normalize(torch.randn(embedding_dim), dim=0)\n",
    "\n",
    "user_embeddings = initial_userembeddings.repeat(num_users, 1)\n",
    "item_embeddings = initial_userembeddings.repeat(num_items, 1)\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "lib = dotdict({\n",
    "    # list of users of each tbatch up to now\n",
    "    'current_tbatches_interactionids': defaultdict(list),\n",
    "    'current_tbatches_user': defaultdict(list),\n",
    "    'current_tbatches_item': defaultdict(list),\n",
    "    'current_tbatches_timestamp': defaultdict(list),\n",
    "    'current_tbatches_feature': defaultdict(list),\n",
    "    'current_tbatches_label': defaultdict(list),\n",
    "    'current_tbatches_previous_item': defaultdict(list),\n",
    "    'current_tbatches_user_timediffs': defaultdict(list),\n",
    "    'current_tbatches_item_timediffs': defaultdict(list),\n",
    "    'current_tbatches_user_timediffs_next': defaultdict(list),\n",
    "    \n",
    "    # the latest tbatch a user is in\n",
    "    'tbatchid_user': defaultdict(lambda: -1),\n",
    "\n",
    "    # the latest tbatch a item is in\n",
    "    'tbatchid_item': defaultdict(lambda: -1),\n",
    "})\n",
    "print(lib.tbatchid_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T10:16:54.782789Z",
     "start_time": "2020-05-07T10:16:54.751530Z"
    }
   },
   "outputs": [],
   "source": [
    "tbatch_start_time = None\n",
    "tbatch_to_insert = -1\n",
    "tbatch_full = False\n",
    "\n",
    "for j in range(train_end_idx):\n",
    "    # READ INTERACTION J\n",
    "    userid = user_sequence_id[j]\n",
    "    itemid = item_sequence_id[j]\n",
    "    feature = feature_sequence[j]\n",
    "    user_timediff = user_timedifference_sequence[j]\n",
    "    item_timediff = item_timedifference_sequence[j]\n",
    "\n",
    "    # CREATE T-BATCHES: ADD INTERACTION J TO THE CORRECT T-BATCH\n",
    "    tbatch_to_insert = max(lib.tbatchid_user[userid], lib.tbatchid_item[itemid]) + 1 \n",
    "    lib.tbatchid_user[userid] = tbatch_to_insert \n",
    "    lib.tbatchid_item[itemid] = tbatch_to_insert\n",
    "\n",
    "    lib.current_tbatches_user[tbatch_to_insert].append(userid)\n",
    "    lib.current_tbatches_item[tbatch_to_insert].append(itemid)\n",
    "    lib.current_tbatches_feature[tbatch_to_insert].append(feature)\n",
    "    lib.current_tbatches_interactionids[tbatch_to_insert].append(j)\n",
    "    lib.current_tbatches_user_timediffs[tbatch_to_insert].append(user_timediff)\n",
    "    lib.current_tbatches_item_timediffs[tbatch_to_insert].append(item_timediff)\n",
    "    lib.current_tbatches_previous_item[tbatch_to_insert].append(user_previous_itemid_sequence[j])\n",
    "\n",
    "    timestamp = timestamp_sequence[j]\n",
    "    if tbatch_start_time is None:\n",
    "        tbatch_start_time = timestamp\n",
    "\n",
    "    # AFTER ALL INTERACTIONS IN THE TIMESPAN ARE CONVERTED TO T-BATCHES, FORWARD PASS TO CREATE EMBEDDING TRAJECTORIES AND CALCULATE PREDICTION LOSS\n",
    "    if timestamp - tbatch_start_time > tbatch_timespan:\n",
    "        break\n",
    "        tbatch_start_time = timestamp # RESET START TIME FOR THE NEXT TBATCHES\n",
    "\n",
    "#         # ITERATE OVER ALL T-BATCHES\n",
    "#         with trange(len(lib.current_tbatches_user)) as progress_bar3:\n",
    "#             for i in progress_bar3:\n",
    "#                 progress_bar3.set_description('Processed %d of %d T-batches ' % (i, len(lib.current_tbatches_user)))\n",
    "\n",
    "#                 total_interaction_count += len(lib.current_tbatches_interactionids[i])\n",
    "\n",
    "#                 # LOAD THE CURRENT TBATCH\n",
    "#                 tbatch_userids = torch.LongTensor(lib.current_tbatches_user[i]).cuda() # Recall \"lib.current_tbatches_user[i]\" has unique elements\n",
    "#                 tbatch_itemids = torch.LongTensor(lib.current_tbatches_item[i]).cuda() # Recall \"lib.current_tbatches_item[i]\" has unique elements\n",
    "#                 tbatch_interactionids = torch.LongTensor(lib.current_tbatches_interactionids[i]).cuda() \n",
    "#                 feature_tensor = Variable(torch.Tensor(lib.current_tbatches_feature[i]).cuda()) # Recall \"lib.current_tbatches_feature[i]\" is list of list, so \"feature_tensor\" is a 2-d tensor\n",
    "#                 user_timediffs_tensor = Variable(torch.Tensor(lib.current_tbatches_user_timediffs[i]).cuda()).unsqueeze(1)\n",
    "#                 item_timediffs_tensor = Variable(torch.Tensor(lib.current_tbatches_item_timediffs[i]).cuda()).unsqueeze(1)\n",
    "#                 tbatch_itemids_previous = torch.LongTensor(lib.current_tbatches_previous_item[i]).cuda()\n",
    "#                 item_embedding_previous = item_embeddings[tbatch_itemids_previous,:]\n",
    "\n",
    "#                 # PROJECT USER EMBEDDING TO CURRENT TIME\n",
    "#                 user_embedding_input = user_embeddings[tbatch_userids,:]\n",
    "#                 user_projected_embedding = model.forward(user_embedding_input, item_embedding_previous, timediffs=user_timediffs_tensor, features=feature_tensor, select='project')\n",
    "#                 user_item_embedding = torch.cat([user_projected_embedding, item_embedding_previous, item_embedding_static[tbatch_itemids_previous,:], user_embedding_static[tbatch_userids,:]], dim=1)\n",
    "\n",
    "#                 # PREDICT NEXT ITEM EMBEDDING                            \n",
    "#                 predicted_item_embedding = model.predict_item_embedding(user_item_embedding)\n",
    "\n",
    "#                 # CALCULATE PREDICTION LOSS\n",
    "#                 item_embedding_input = item_embeddings[tbatch_itemids,:]\n",
    "#                 loss += MSELoss(predicted_item_embedding, torch.cat([item_embedding_input, item_embedding_static[tbatch_itemids,:]], dim=1).detach())\n",
    "\n",
    "#                 # UPDATE DYNAMIC EMBEDDINGS AFTER INTERACTION\n",
    "#                 user_embedding_output = model.forward(user_embedding_input, item_embedding_input, timediffs=user_timediffs_tensor, features=feature_tensor, select='user_update')\n",
    "#                 item_embedding_output = model.forward(user_embedding_input, item_embedding_input, timediffs=item_timediffs_tensor, features=feature_tensor, select='item_update')\n",
    "\n",
    "#                 item_embeddings[tbatch_itemids,:] = item_embedding_output\n",
    "#                 user_embeddings[tbatch_userids,:] = user_embedding_output  \n",
    "\n",
    "#                 user_embeddings_timeseries[tbatch_interactionids,:] = user_embedding_output\n",
    "#                 item_embeddings_timeseries[tbatch_interactionids,:] = item_embedding_output\n",
    "\n",
    "#                 # CALCULATE LOSS TO MAINTAIN TEMPORAL SMOOTHNESS\n",
    "#                 loss += MSELoss(item_embedding_output, item_embedding_input.detach())\n",
    "#                 loss += MSELoss(user_embedding_output, user_embedding_input.detach())\n",
    "\n",
    "#                 # CALCULATE STATE CHANGE LOSS\n",
    "#                 if args.state_change:\n",
    "#                     loss += calculate_state_prediction_loss(model, tbatch_interactionids, user_embeddings_timeseries, y_true, crossEntropyLoss) \n",
    "\n",
    "#         # BACKPROPAGATE ERROR AFTER END OF T-BATCH\n",
    "#         total_loss += loss.item()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # RESET LOSS FOR NEXT T-BATCH\n",
    "#         loss = 0\n",
    "#         item_embeddings.detach_() # Detachment is needed to prevent double propagation of gradient\n",
    "#         user_embeddings.detach_()\n",
    "#         item_embeddings_timeseries.detach_() \n",
    "#         user_embeddings_timeseries.detach_()\n",
    "\n",
    "#         # REINITIALIZE\n",
    "#         reinitialize_tbatches()\n",
    "#         tbatch_to_insert = -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T10:19:07.912113Z",
     "start_time": "2020-05-07T10:19:07.905708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 55 55\n"
     ]
    }
   ],
   "source": [
    "print(len(lib.current_tbatches_user), len(lib.current_tbatches_item), len(lib.current_tbatches_interactionids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T10:28:14.763349Z",
     "start_time": "2020-05-07T10:28:14.694984Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "tbatch_userids = torch.LongTensor(lib.current_tbatches_user[i])\n",
    "tbatch_itemids = torch.LongTensor(lib.current_tbatches_item[i])\n",
    "tbatch_interactionids = torch.LongTensor(lib.current_tbatches_interactionids[i]) \n",
    "feature_tensor = (torch.Tensor(lib.current_tbatches_feature[i]))\n",
    "user_timediffs_tensor = (torch.Tensor(lib.current_tbatches_user_timediffs[i])).unsqueeze(1)\n",
    "item_timediffs_tensor = (torch.Tensor(lib.current_tbatches_item_timediffs[i])).unsqueeze(1)\n",
    "tbatch_itemids_previous = torch.LongTensor(lib.current_tbatches_previous_item[i])\n",
    "item_embedding_previous = item_embeddings[tbatch_itemids_previous,:]\n",
    "print(tbatch_userids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T11:26:00.888950Z",
     "start_time": "2020-05-07T11:26:00.880409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n",
      "torch.Size([31, 128])\n",
      "torch.Size([31, 1])\n",
      "torch.Size([31, 1])\n",
      "torch.Size([31, 73])\n"
     ]
    }
   ],
   "source": [
    "user_embedding_input = user_embeddings[tbatch_userids,:]\n",
    "item_embedding_input = item_embeddings[tbatch_itemids,:]\n",
    "print(user_embedding_input.size())\n",
    "print(item_embedding_input.size())\n",
    "print(user_timediffs_tensor.size())\n",
    "print(item_timediffs_tensor.size())\n",
    "print(feature_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T11:12:55.246355Z",
     "start_time": "2020-05-07T11:12:55.233354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n",
      "torch.Size([128]) torch.Size([128]) torch.Size([1]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "for ue, ie, ut, it in zip(torch.unbind(user_embedding_input, 0), torch.unbind(item_embedding_input, 0), torch.unbind(user_timediffs_tensor, 0), torch.unbind(item_timediffs_tensor, 0)):\n",
    "    print(ue.size(), ie.size(), ut.size(), it.size())\n",
    "    output.append(torch.randn(128))\n",
    "output = torch.stack(output, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T11:12:58.276643Z",
     "start_time": "2020-05-07T11:12:58.271177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31, 128])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-07T11:13:00.604817Z",
     "start_time": "2020-05-07T11:13:00.598890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31, 128])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embedding_input.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test dynamic embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T19:36:06.292176Z",
     "start_time": "2020-05-17T19:36:06.267413Z"
    }
   },
   "outputs": [],
   "source": [
    "class NormalLinear(nn.Linear):\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.normal_(0, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.normal_(0, stdv)\n",
    "\n",
    "class CustomCell(nn.Module):\n",
    "    def __init__(self, embedding_size, feature_size):\n",
    "        super(CustomCell, self).__init__()\n",
    "        self.embsz = embedding_size\n",
    "        self.uembsz = embedding_size\n",
    "        self.iembsz = embedding_size\n",
    "        self.featsz = feature_size\n",
    "        self.N = 3*embedding_size + feature_size + 1\n",
    "        self.WdynU1 = torch.nn.Parameter(torch.randn(embedding_size, self.uembsz, self.N))\n",
    "        self.WdynU2 = torch.nn.Parameter(torch.randn(embedding_size, self.uembsz, self.N))\n",
    "        self.WdynI1 = torch.nn.Parameter(torch.randn(embedding_size, self.iembsz, self.N))\n",
    "        self.WdynF  = torch.nn.Parameter(torch.randn(embedding_size, self.featsz, self.N))\n",
    "        self.WdynT  = torch.nn.Parameter(torch.randn(embedding_size, 1, self.N))\n",
    "        \n",
    "        ### this parameter remains unused in ItemRNN. Wastes GPU Space.\n",
    "        ### Probably find some better place for this?\n",
    "        self.WdynP = torch.nn.Parameter(torch.randn(embedding_size, self.uembsz, self.N))\n",
    "    \n",
    "    def forward(self, U1, U2, I1, F, T):\n",
    "        ntensor = torch.cat([U1, U2, I1, F, T]).unsqueeze(1)\n",
    "        W1 = torch.mm(self.WdynU1.view(self.embsz * self.uembsz, -1), ntensor).view(self.embsz, self.uembsz, -1)\n",
    "        W2 = torch.mm(self.WdynU2.view(self.embsz * self.uembsz, -1), ntensor).view(self.embsz, self.uembsz, -1)\n",
    "        W3 = torch.mm(self.WdynI1.view(self.embsz * self.iembsz, -1), ntensor).view(self.embsz, self.iembsz, -1)\n",
    "        W4 = torch.mm(self.WdynF.view(self.embsz * self.featsz, -1), ntensor).view(self.embsz, self.featsz, -1)\n",
    "        W5 = torch.mm(self.WdynT.view(self.embsz * 1, -1), ntensor).view(self.embsz, 1, -1)\n",
    "\n",
    "        ### All N_i's are of same size\n",
    "        N_1 = torch.tanh(torch.mm(W1.squeeze(2), U1.unsqueeze(1)))\n",
    "        N_2 = torch.tanh(torch.mm(W2.squeeze(2), U2.unsqueeze(1)))\n",
    "        N_3 = torch.tanh(torch.mm(W3.squeeze(2), I1.unsqueeze(1)))\n",
    "        N_4 = torch.tanh(torch.mm(W4.squeeze(2), F.unsqueeze(1)))\n",
    "        N_5 = torch.tanh(torch.mm(W5.squeeze(2), T.unsqueeze(1)))\n",
    "        \n",
    "        ### Perform predictions over this interaction\n",
    "        user_predicted, item_predicted = self.predict_(U1, U2, I1, F, T)\n",
    "        \n",
    "        # return the sum of all N_i's as new embedding\n",
    "        return torch.sum(torch.stack([N_1, N_2, N_3, N_4, N_5], dim=1), dim=1), user_predicted, item_predicted\n",
    "    \n",
    "    def project_user(self, U1_, U2_, I1_, F_, delta):\n",
    "        # Predict embedding of user U1 from it's embedding at U_ at T-\n",
    "        ntensor = torch.cat([U1_, U2_, I1_, F_, delta]).unsqueeze(1)\n",
    "        W5 = torch.mm(self.WdynT.view(self.embsz * 1, -1), ntensor).view(self.embsz, 1, -1)\n",
    "        N_5 = torch.tanh(torch.mm(W5.squeeze(2), delta.unsqueeze(1)))\n",
    "        predicted_u = (1. + N_5).squeeze(1) * U1_\n",
    "        return predicted_u\n",
    "    \n",
    "    def predict_(self, U1_, U2_, I1_, F_, delta):\n",
    "        user_hat = self.project_user(U1_, U2_, I1_, F_, delta)\n",
    "        ntensor = torch.cat([U1_, U2_, I1_, F_, delta]).unsqueeze(1)\n",
    "        W6 = torch.mm(self.WdynP.view(self.embsz * self.uembsz, -1), ntensor).view(self.embsz, self.uembsz, -1)\n",
    "        item_hat = torch.tanh(torch.mm(W6.squeeze(2), user_hat.unsqueeze(1)))\n",
    "        return user_hat, item_hat\n",
    "    \n",
    "\n",
    "class Wrapper(nn.Module):\n",
    "    def __init__(self, emb_sz, feat_sz):\n",
    "        super(Wrapper, self).__init__()\n",
    "        self.cell = CustomCell(emb_sz, feat_sz)\n",
    "    \n",
    "    def forward(self, BU1, BU2, BI1, BF, BT):\n",
    "        ### Input is batched. Unroll the TBatch and train for every timestep\n",
    "        output = []\n",
    "        user_predicted = []\n",
    "        item_predicted = []\n",
    "        for ue, oe, ie, fv, delta in zip(torch.unbind(BU1, 0), torch.unbind(BU2, 0), torch.unbind(BI1, 0), torch.unbind(BF, 0), torch.unbind(BT, 0)):\n",
    "            new_embedding, u_predicted, i_predicted = self.cell(ue, oe, ie, fv, delta)\n",
    "            output.append(new_embedding)\n",
    "            user_predicted.append(u_predicted)\n",
    "            item_predicted.append(i_predicted)\n",
    "        output = torch.stack(output, dim=0).squeeze()\n",
    "        user_predicted = torch.stack(user_predicted, dim=0).squeeze()\n",
    "        item_predicted = torch.stack(item_predicted, dim=0).squeeze()\n",
    "        return output, user_predicted, item_predicted\n",
    "\n",
    "class DynaEmbedModel(nn.Module):\n",
    "    def __init__(self, emb_sz, feat_sz):\n",
    "        super(DynaEmbedModel, self).__init__()\n",
    "        print(\"*** Initializing the DYNAEMBED model ***\")\n",
    "        self.userrnn = Wrapper(emb_sz, feat_sz)\n",
    "        self.itemrnn = Wrapper(emb_sz, feat_sz)\n",
    "        print(\"*** DYNAEMBED initialization complete ***\\n\\n\")\n",
    "    \n",
    "    def forward(self, BU1, BU2, BI1, BF, BT, perform='predict'):\n",
    "        # return new user, item and other user embedding\n",
    "        if perform=='interacting_user':\n",
    "            BU1_new, BU1_predicted, I1_predicted = self.userrnn(BU1, BU2, BI1, BF, BT)\n",
    "            return BU1_new, BU1_predicted, I1_predicted\n",
    "        elif perform == 'interacted_user':\n",
    "            BU2_new, _, __ = self.userrnn(BU2, BU1, BI1, BF, BT)\n",
    "            return BU2_new\n",
    "        elif perform == 'item':\n",
    "            BI1_new, _, __ = self.itemrnn(BU1, BU2, BI1, BF, BT)\n",
    "            return BI1_new\n",
    "        elif perform=='predict':\n",
    "            _, BU1_predicted, I1_predicted = self.userrnn(BU1, BU2, BI1, BF, BT)\n",
    "            return BU1_predicted, I1_predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T19:36:10.196232Z",
     "start_time": "2020-05-17T19:36:07.066409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Initializing the DYNAEMBED model ***\n",
      "*** DYNAEMBED initialization complete ***\n",
      "\n",
      "\n",
      "5.725464820861816\n"
     ]
    }
   ],
   "source": [
    "sample_user_embedding_input = torch.randn(31, 128)\n",
    "sample_item_embedding_input = torch.randn(31, 128)\n",
    "sample_op_embedding_input   = torch.randn(31, 128)\n",
    "sample_feature_input        = torch.randn(31, 73)\n",
    "sample_time_diff            = torch.randn(31, 1)\n",
    "\n",
    "# model = Wrapper(128, 73)\n",
    "model = DynaEmbedModel(128, 73)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "### perform one step for the sample tbatch user update\n",
    "optimizer.zero_grad()\n",
    "\n",
    "### Forward pass\n",
    "output, _2, _3 = model(sample_user_embedding_input, sample_op_embedding_input, sample_item_embedding_input, sample_feature_input, sample_time_diff, 'interacting_user')\n",
    "\n",
    "### Compute loss\n",
    "loss = criterion(output, sample_user_embedding_input)\n",
    "\n",
    "### Backpropagation (through time?)\n",
    "loss.backward()\n",
    "\n",
    "### Update parameters\n",
    "optimizer.step()\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-17T19:23:34.574977Z",
     "start_time": "2020-05-17T19:23:34.570333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31, 128])\n",
      "torch.Size([31, 128])\n",
      "torch.Size([31, 128])\n",
      "torch.Size([31, 128])\n",
      "torch.Size([31, 128])\n"
     ]
    }
   ],
   "source": [
    "print(output.size())\n",
    "print(_2.size())\n",
    "print(_3.size())\n",
    "print(_4.size())\n",
    "print(_5.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_env",
   "language": "python",
   "name": "py3_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
